{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d99d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd8538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human 1: Hi!\n",
      "Human 2: What is your favorite holiday?\n",
      "Human 1: one where I get to meet lots of different people.\n",
      "Human 2: What was the most number of people you have ever met during a holiday?\n",
      "Human 1: Hard to keep a count. Maybe 25.\n",
      "Human 2: Which holiday was that?\n",
      "Human 1: I think it was Australia\n",
      "Human 2: Do you still talk to the people you met?\n",
      "Human 1: Not really. The interactions are usually short-lived but it's fascinating to learn where people are coming from and what matters to them\n",
      "Human 2: Yea, me too. I feel like God often puts strangers in front of you, and gives you an opportunity to connect with them in that moment in deeply meaningful ways. Do you ever feel like you know things about strangers without them telling you?\n",
      "Human 1: what do you mean?\n",
      "Human 2: I think it's like a 6th sense, often seen as \"cold readings\" to people, but can be remarkably accurate. I once sat next to a man in a coffee and I felt a pain in my back. I asked the stranger if he had a pain. It turns o\n"
     ]
    }
   ],
   "source": [
    "file = Path.cwd() / 'human_chat.txt'\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3fba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"%&'()*+,-./012345679:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\_abcdefghijklmnopqrstuvwxyz~√©‚Äô‚Äú‚Äù‚Ä¶ÊπòÁïôÔºâÔºöüòÄüòÇüòÜüòâüòêüòõüòûüôÇ\n"
     ]
    }
   ],
   "source": [
    "# all unique characters that occur in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1f4a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 65, 65, 1, 76, 64, 61, 74, 61, 2]\n",
      "hii there!\n"
     ]
    }
   ],
   "source": [
    "# string to integer\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "# integer to string\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: receive string, output a list of integers\n",
    "decode = lambda l:''.join([itos[i] for i in l]) # decoder: receive a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there!\"))\n",
    "print(decode(encode(\"hii there!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b0ec73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([115782]) torch.int64\n",
      "tensor([36, 77, 69, 57, 70,  1, 16, 24,  1, 36, 65,  2,  0, 36, 77, 69, 57, 70,\n",
      "         1, 17, 24,  1, 51, 64, 57, 76,  1, 65, 75,  1, 81, 71, 77, 74,  1, 62,\n",
      "        57, 78, 71, 74, 65, 76, 61,  1, 64, 71, 68, 65, 60, 57, 81, 28,  0, 36,\n",
      "        77, 69, 57, 70,  1, 16, 24,  1, 71, 70, 61,  1, 79, 64, 61, 74, 61,  1,\n",
      "        37,  1, 63, 61, 76,  1, 76, 71,  1, 69, 61, 61, 76,  1, 68, 71, 76, 75,\n",
      "         1, 71, 62,  1, 60, 65, 62, 62, 61, 74, 61, 70, 76,  1, 72, 61, 71, 72,\n",
      "        68, 61, 13,  0, 36, 77, 69, 57, 70,  1, 17, 24,  1, 51, 64, 57, 76,  1,\n",
      "        79, 57, 75,  1, 76, 64, 61,  1, 69, 71, 75, 76,  1, 70, 77, 69, 58, 61,\n",
      "        74,  1, 71, 62,  1, 72, 61, 71, 72, 68, 61,  1, 81, 71, 77,  1, 64, 57,\n",
      "        78, 61,  1, 61, 78, 61, 74,  1, 69, 61, 76,  1, 60, 77, 74, 65, 70, 63,\n",
      "         1, 57,  1, 64, 71, 68, 65, 60, 57, 81, 28,  0, 36, 77, 69, 57, 70,  1,\n",
      "        16, 24,  1, 36, 57, 74, 60,  1, 76, 71,  1, 67, 61, 61, 72,  1, 57,  1,\n",
      "        59, 71, 77, 70, 76, 13,  1, 41, 57, 81, 58, 61,  1, 17, 20, 13,  0, 36,\n",
      "        77, 69, 57, 70,  1, 17, 24,  1, 51, 64, 65, 59, 64,  1, 64, 71, 68, 65,\n",
      "        60, 57, 81,  1, 79, 57, 75,  1, 76, 64, 57, 76, 28,  0, 36, 77, 69, 57,\n",
      "        70,  1, 16, 24,  1, 37,  1, 76, 64, 65, 70, 67,  1, 65, 76,  1, 79, 57,\n",
      "        75,  1, 29, 77, 75, 76, 74, 57, 68, 65, 57,  0, 36, 77, 69, 57, 70,  1,\n",
      "        17, 24,  1, 32, 71,  1, 81, 71, 77,  1, 75, 76, 65, 68, 68,  1, 76, 57,\n",
      "        68, 67,  1, 76, 71,  1, 76, 64, 61,  1, 72, 61, 71, 72, 68, 61,  1, 81,\n",
      "        71, 77,  1, 69, 61, 76, 28,  0, 36, 77, 69, 57, 70,  1, 16, 24,  1, 42,\n",
      "        71, 76,  1, 74, 61, 57, 68, 68, 81, 13,  1, 48, 64, 61,  1, 65, 70, 76,\n",
      "        61, 74, 57, 59, 76, 65, 71, 70, 75,  1, 57, 74, 61,  1, 77, 75, 77, 57,\n",
      "        68, 68, 81,  1, 75, 64, 71, 74, 76, 12, 68, 65, 78, 61, 60,  1, 58, 77,\n",
      "        76,  1, 65, 76,  6, 75,  1, 62, 57, 75, 59, 65, 70, 57, 76, 65, 70, 63,\n",
      "         1, 76, 71,  1, 68, 61, 57, 74, 70,  1, 79, 64, 61, 74, 61,  1, 72, 61,\n",
      "        71, 72, 68, 61,  1, 57, 74, 61,  1, 59, 71, 69, 65, 70, 63,  1, 62, 74,\n",
      "        71, 69,  1, 57, 70, 60,  1, 79, 64, 57, 76,  1, 69, 57, 76, 76, 61, 74,\n",
      "        75,  1, 76, 71,  1, 76, 64, 61, 69,  0, 36, 77, 69, 57, 70,  1, 17, 24,\n",
      "         1, 53, 61, 57, 11,  1, 69, 61,  1, 76, 71, 71, 13,  1, 37,  1, 62, 61,\n",
      "        61, 68,  1, 68, 65, 67, 61,  1, 35, 71, 60,  1, 71, 62, 76, 61, 70,  1,\n",
      "        72, 77, 76, 75,  1, 75, 76, 74, 57, 70, 63, 61, 74, 75,  1, 65, 70,  1,\n",
      "        62, 74, 71, 70, 76,  1, 71, 62,  1, 81, 71, 77, 11,  1, 57, 70, 60,  1,\n",
      "        63, 65, 78, 61, 75,  1, 81, 71, 77,  1, 57, 70,  1, 71, 72, 72, 71, 74,\n",
      "        76, 77, 70, 65, 76, 81,  1, 76, 71,  1, 59, 71, 70, 70, 61, 59, 76,  1,\n",
      "        79, 65, 76, 64,  1, 76, 64, 61, 69,  1, 65, 70,  1, 76, 64, 57, 76,  1,\n",
      "        69, 71, 69, 61, 70, 76,  1, 65, 70,  1, 60, 61, 61, 72, 68, 81,  1, 69,\n",
      "        61, 57, 70, 65, 70, 63, 62, 77, 68,  1, 79, 57, 81, 75, 13,  1, 32, 71,\n",
      "         1, 81, 71, 77,  1, 61, 78, 61, 74,  1, 62, 61, 61, 68,  1, 68, 65, 67,\n",
      "        61,  1, 81, 71, 77,  1, 67, 70, 71, 79,  1, 76, 64, 65, 70, 63, 75,  1,\n",
      "        57, 58, 71, 77, 76,  1, 75, 76, 74, 57, 70, 63, 61, 74, 75,  1, 79, 65,\n",
      "        76, 64, 71, 77, 76,  1, 76, 64, 61, 69,  1, 76, 61, 68, 68, 65, 70, 63,\n",
      "         1, 81, 71, 77, 28,  0, 36, 77, 69, 57, 70,  1, 16, 24,  1, 79, 64, 57,\n",
      "        76,  1, 60, 71,  1, 81, 71, 77,  1, 69, 61, 57, 70, 28,  0, 36, 77, 69,\n",
      "        57, 70,  1, 17, 24,  1, 37,  1, 76, 64, 65, 70, 67,  1, 65, 76,  6, 75,\n",
      "         1, 68, 65, 67, 61,  1, 57,  1, 21, 76, 64,  1, 75, 61, 70, 75, 61, 11,\n",
      "         1, 71, 62, 76, 61, 70,  1, 75, 61, 61, 70,  1, 57, 75,  1,  3, 59, 71,\n",
      "        68, 60,  1, 74, 61, 57, 60, 65, 70, 63, 75,  3,  1, 76, 71,  1, 72, 61,\n",
      "        71, 72, 68, 61, 11,  1, 58, 77, 76,  1, 59, 57, 70,  1, 58, 61,  1, 74,\n",
      "        61, 69, 57, 74, 67, 57, 58, 68, 81,  1, 57, 59, 59, 77, 74, 57, 76, 61,\n",
      "        13,  1, 37,  1, 71, 70, 59, 61,  1, 75, 57, 76,  1, 70, 61, 80, 76,  1,\n",
      "        76, 71,  1, 57,  1, 69, 57, 70,  1, 65, 70,  1, 57,  1, 59, 71, 62, 62,\n",
      "        61, 61,  1, 57, 70, 60,  1, 37,  1, 62, 61, 68, 76,  1, 57,  1, 72, 57,\n",
      "        65, 70,  1, 65, 70,  1, 69, 81,  1, 58, 57, 59, 67, 13,  1, 37,  1, 57,\n",
      "        75, 67, 61, 60,  1, 76, 64, 61,  1, 75, 76, 74, 57, 70, 63, 61, 74,  1,\n",
      "        65, 62,  1, 64, 61,  1, 64, 57, 60,  1, 57,  1, 72, 57, 65, 70, 13,  1,\n",
      "        37, 76,  1, 76, 77, 74, 70, 75,  1, 71])\n"
     ]
    }
   ],
   "source": [
    "import torch # PyTorch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60af087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # 90% of text will be for training\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4471ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36, 77, 69, 57, 70,  1, 16, 24,  1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a78d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([36]) the target: 77\n",
      "when input is tensor([36, 77]) the target: 69\n",
      "when input is tensor([36, 77, 69]) the target: 57\n",
      "when input is tensor([36, 77, 69, 57]) the target: 70\n",
      "when input is tensor([36, 77, 69, 57, 70]) the target: 1\n",
      "when input is tensor([36, 77, 69, 57, 70,  1]) the target: 16\n",
      "when input is tensor([36, 77, 69, 57, 70,  1, 16]) the target: 24\n",
      "when input is tensor([36, 77, 69, 57, 70,  1, 16, 24]) the target: 1\n"
     ]
    }
   ],
   "source": [
    "# showing how the prediction works\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cddcaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[71, 79,  1, 79, 64, 61, 70,  1],\n",
      "        [77,  1, 72, 68, 57, 70, 70, 65],\n",
      "        [ 1, 76, 71,  1, 75, 67, 65,  1],\n",
      "        [68,  1, 60, 77, 74, 65, 70, 63]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[79,  1, 79, 64, 61, 70,  1, 81],\n",
      "        [ 1, 72, 68, 57, 70, 70, 65, 70],\n",
      "        [76, 71,  1, 75, 67, 65,  1, 58],\n",
      "        [ 1, 60, 77, 74, 65, 70, 63,  1]])\n",
      "-------\n",
      "when input is [71] the target: 79\n",
      "when input is [71, 79] the target: 1\n",
      "when input is [71, 79, 1] the target: 79\n",
      "when input is [71, 79, 1, 79] the target: 64\n",
      "when input is [71, 79, 1, 79, 64] the target: 61\n",
      "when input is [71, 79, 1, 79, 64, 61] the target: 70\n",
      "when input is [71, 79, 1, 79, 64, 61, 70] the target: 1\n",
      "when input is [71, 79, 1, 79, 64, 61, 70, 1] the target: 81\n",
      "when input is [77] the target: 1\n",
      "when input is [77, 1] the target: 72\n",
      "when input is [77, 1, 72] the target: 68\n",
      "when input is [77, 1, 72, 68] the target: 57\n",
      "when input is [77, 1, 72, 68, 57] the target: 70\n",
      "when input is [77, 1, 72, 68, 57, 70] the target: 70\n",
      "when input is [77, 1, 72, 68, 57, 70, 70] the target: 65\n",
      "when input is [77, 1, 72, 68, 57, 70, 70, 65] the target: 70\n",
      "when input is [1] the target: 76\n",
      "when input is [1, 76] the target: 71\n",
      "when input is [1, 76, 71] the target: 1\n",
      "when input is [1, 76, 71, 1] the target: 75\n",
      "when input is [1, 76, 71, 1, 75] the target: 67\n",
      "when input is [1, 76, 71, 1, 75, 67] the target: 65\n",
      "when input is [1, 76, 71, 1, 75, 67, 65] the target: 1\n",
      "when input is [1, 76, 71, 1, 75, 67, 65, 1] the target: 58\n",
      "when input is [68] the target: 1\n",
      "when input is [68, 1] the target: 60\n",
      "when input is [68, 1, 60] the target: 77\n",
      "when input is [68, 1, 60, 77] the target: 74\n",
      "when input is [68, 1, 60, 77, 74] the target: 65\n",
      "when input is [68, 1, 60, 77, 74, 65] the target: 70\n",
      "when input is [68, 1, 60, 77, 74, 65, 70] the target: 63\n",
      "when input is [68, 1, 60, 77, 74, 65, 70, 63] the target: 1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4 # number of independent sequences being processed\n",
    "block_size = 8 # maximum context length for predictions\n",
    "\n",
    "# generates a batch of data\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dfa72d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 101])\n",
      "tensor(5.2804, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token reads off the logits for the next token\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets):\n",
    "        \n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        B, T, C = logits.shape\n",
    "        # adjusting to match cross_entropy\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        \n",
    "        # checking quality of predictions\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate():\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd772dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
