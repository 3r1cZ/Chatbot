{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d99d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd8538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human 1: Hi!\n",
      "Human 2: What is your favorite holiday?\n",
      "Human 1: one where I get to meet lots of different people.\n",
      "Human 2: What was the most number of people you have ever met during a holiday?\n",
      "Human 1: Hard to keep a count. Maybe 25.\n",
      "Human 2: Which holiday was that?\n",
      "Human 1: I think it was Australia\n",
      "Human 2: Do you still talk to the people you met?\n",
      "Human 1: Not really. The interactions are usually short-lived but it's fascinating to learn where people are coming from and what matters to them\n",
      "Human 2: Yea, me too. I feel like God often puts strangers in front of you, and gives you an opportunity to connect with them in that moment in deeply meaningful ways. Do you ever feel like you know things about strangers without them telling you?\n",
      "Human 1: what do you mean?\n",
      "Human 2: I think it's like a 6th sense, often seen as \"cold readings\" to people, but can be remarkably accurate. I once sat next to a man in a coffee and I felt a pain in my back. I asked the stranger if he had a pain. It turns o\n"
     ]
    }
   ],
   "source": [
    "file = Path.cwd() / 'human_chat.txt'\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3fba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"%&'()*+,-./012345679:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\_abcdefghijklmnopqrstuvwxyz~√©‚Äô‚Äú‚Äù‚Ä¶ÊπòÁïôÔºâÔºöüòÄüòÇüòÜüòâüòêüòõüòûüôÇ\n"
     ]
    }
   ],
   "source": [
    "# all unique characters that occur in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1f4a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 65, 65, 1, 76, 64, 61, 74, 61, 2]\n",
      "hii there!\n"
     ]
    }
   ],
   "source": [
    "# string to integer\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "# integer to string\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: receive string, output a list of integers\n",
    "decode = lambda l:''.join([itos[i] for i in l]) # decoder: receive a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there!\"))\n",
    "print(decode(encode(\"hii there!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0ec73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([115782]) torch.int64\n",
      "tensor([36, 77, 69, 57, 70,  1, 16, 24,  1, 36, 65,  2,  0, 36, 77, 69, 57, 70,\n",
      "         1, 17, 24,  1, 51, 64, 57, 76,  1, 65, 75,  1, 81, 71, 77, 74,  1, 62,\n",
      "        57, 78, 71, 74, 65, 76, 61,  1, 64, 71, 68, 65, 60, 57, 81, 28,  0, 36,\n",
      "        77, 69, 57, 70,  1, 16, 24,  1, 71, 70, 61,  1, 79, 64, 61, 74, 61,  1,\n",
      "        37,  1, 63, 61, 76,  1, 76, 71,  1, 69, 61, 61, 76,  1, 68, 71, 76, 75,\n",
      "         1, 71, 62,  1, 60, 65, 62, 62, 61, 74, 61, 70, 76,  1, 72, 61, 71, 72,\n",
      "        68, 61, 13,  0, 36, 77, 69, 57, 70,  1, 17, 24,  1, 51, 64, 57, 76,  1,\n",
      "        79, 57, 75,  1, 76, 64, 61,  1, 69, 71, 75, 76,  1, 70, 77, 69, 58, 61,\n",
      "        74,  1, 71, 62,  1, 72, 61, 71, 72, 68, 61,  1, 81, 71, 77,  1, 64, 57,\n",
      "        78, 61,  1, 61, 78, 61, 74,  1, 69, 61, 76,  1, 60, 77, 74, 65, 70, 63,\n",
      "         1, 57,  1, 64, 71, 68, 65, 60, 57, 81, 28,  0, 36, 77, 69, 57, 70,  1,\n",
      "        16, 24,  1, 36, 57, 74, 60,  1, 76, 71,  1, 67, 61, 61, 72,  1, 57,  1,\n",
      "        59, 71, 77, 70, 76, 13,  1, 41, 57, 81, 58, 61,  1, 17, 20, 13,  0, 36,\n",
      "        77, 69, 57, 70,  1, 17, 24,  1, 51, 64, 65, 59, 64,  1, 64, 71, 68, 65,\n",
      "        60, 57, 81,  1, 79, 57, 75,  1, 76, 64, 57, 76, 28,  0, 36, 77, 69, 57,\n",
      "        70,  1, 16, 24,  1, 37,  1, 76, 64, 65, 70, 67,  1, 65, 76,  1, 79, 57,\n",
      "        75,  1, 29, 77, 75, 76, 74, 57, 68, 65, 57,  0, 36, 77, 69, 57, 70,  1,\n",
      "        17, 24,  1, 32, 71,  1, 81, 71, 77,  1, 75, 76, 65, 68, 68,  1, 76, 57,\n",
      "        68, 67,  1, 76, 71,  1, 76, 64, 61,  1, 72, 61, 71, 72, 68, 61,  1, 81,\n",
      "        71, 77,  1, 69, 61, 76, 28,  0, 36, 77, 69, 57, 70,  1, 16, 24,  1, 42,\n",
      "        71, 76,  1, 74, 61, 57, 68, 68, 81, 13,  1, 48, 64, 61,  1, 65, 70, 76,\n",
      "        61, 74, 57, 59, 76, 65, 71, 70, 75,  1, 57, 74, 61,  1, 77, 75, 77, 57,\n",
      "        68, 68, 81,  1, 75, 64, 71, 74, 76, 12, 68, 65, 78, 61, 60,  1, 58, 77,\n",
      "        76,  1, 65, 76,  6, 75,  1, 62, 57, 75, 59, 65, 70, 57, 76, 65, 70, 63,\n",
      "         1, 76, 71,  1, 68, 61, 57, 74, 70,  1, 79, 64, 61, 74, 61,  1, 72, 61,\n",
      "        71, 72, 68, 61,  1, 57, 74, 61,  1, 59, 71, 69, 65, 70, 63,  1, 62, 74,\n",
      "        71, 69,  1, 57, 70, 60,  1, 79, 64, 57, 76,  1, 69, 57, 76, 76, 61, 74,\n",
      "        75,  1, 76, 71,  1, 76, 64, 61, 69,  0, 36, 77, 69, 57, 70,  1, 17, 24,\n",
      "         1, 53, 61, 57, 11,  1, 69, 61,  1, 76, 71, 71, 13,  1, 37,  1, 62, 61,\n",
      "        61, 68,  1, 68, 65, 67, 61,  1, 35, 71, 60,  1, 71, 62, 76, 61, 70,  1,\n",
      "        72, 77, 76, 75,  1, 75, 76, 74, 57, 70, 63, 61, 74, 75,  1, 65, 70,  1,\n",
      "        62, 74, 71, 70, 76,  1, 71, 62,  1, 81, 71, 77, 11,  1, 57, 70, 60,  1,\n",
      "        63, 65, 78, 61, 75,  1, 81, 71, 77,  1, 57, 70,  1, 71, 72, 72, 71, 74,\n",
      "        76, 77, 70, 65, 76, 81,  1, 76, 71,  1, 59, 71, 70, 70, 61, 59, 76,  1,\n",
      "        79, 65, 76, 64,  1, 76, 64, 61, 69,  1, 65, 70,  1, 76, 64, 57, 76,  1,\n",
      "        69, 71, 69, 61, 70, 76,  1, 65, 70,  1, 60, 61, 61, 72, 68, 81,  1, 69,\n",
      "        61, 57, 70, 65, 70, 63, 62, 77, 68,  1, 79, 57, 81, 75, 13,  1, 32, 71,\n",
      "         1, 81, 71, 77,  1, 61, 78, 61, 74,  1, 62, 61, 61, 68,  1, 68, 65, 67,\n",
      "        61,  1, 81, 71, 77,  1, 67, 70, 71, 79,  1, 76, 64, 65, 70, 63, 75,  1,\n",
      "        57, 58, 71, 77, 76,  1, 75, 76, 74, 57, 70, 63, 61, 74, 75,  1, 79, 65,\n",
      "        76, 64, 71, 77, 76,  1, 76, 64, 61, 69,  1, 76, 61, 68, 68, 65, 70, 63,\n",
      "         1, 81, 71, 77, 28,  0, 36, 77, 69, 57, 70,  1, 16, 24,  1, 79, 64, 57,\n",
      "        76,  1, 60, 71,  1, 81, 71, 77,  1, 69, 61, 57, 70, 28,  0, 36, 77, 69,\n",
      "        57, 70,  1, 17, 24,  1, 37,  1, 76, 64, 65, 70, 67,  1, 65, 76,  6, 75,\n",
      "         1, 68, 65, 67, 61,  1, 57,  1, 21, 76, 64,  1, 75, 61, 70, 75, 61, 11,\n",
      "         1, 71, 62, 76, 61, 70,  1, 75, 61, 61, 70,  1, 57, 75,  1,  3, 59, 71,\n",
      "        68, 60,  1, 74, 61, 57, 60, 65, 70, 63, 75,  3,  1, 76, 71,  1, 72, 61,\n",
      "        71, 72, 68, 61, 11,  1, 58, 77, 76,  1, 59, 57, 70,  1, 58, 61,  1, 74,\n",
      "        61, 69, 57, 74, 67, 57, 58, 68, 81,  1, 57, 59, 59, 77, 74, 57, 76, 61,\n",
      "        13,  1, 37,  1, 71, 70, 59, 61,  1, 75, 57, 76,  1, 70, 61, 80, 76,  1,\n",
      "        76, 71,  1, 57,  1, 69, 57, 70,  1, 65, 70,  1, 57,  1, 59, 71, 62, 62,\n",
      "        61, 61,  1, 57, 70, 60,  1, 37,  1, 62, 61, 68, 76,  1, 57,  1, 72, 57,\n",
      "        65, 70,  1, 65, 70,  1, 69, 81,  1, 58, 57, 59, 67, 13,  1, 37,  1, 57,\n",
      "        75, 67, 61, 60,  1, 76, 64, 61,  1, 75, 76, 74, 57, 70, 63, 61, 74,  1,\n",
      "        65, 62,  1, 64, 61,  1, 64, 57, 60,  1, 57,  1, 72, 57, 65, 70, 13,  1,\n",
      "        37, 76,  1, 76, 77, 74, 70, 75,  1, 71])\n"
     ]
    }
   ],
   "source": [
    "import torch # PyTorch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60af087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # 90% of text will be for training\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4471ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36, 77, 69, 57, 70,  1, 16, 24,  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a78d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([36]) the target: 77\n",
      "when input is tensor([36, 77]) the target: 69\n",
      "when input is tensor([36, 77, 69]) the target: 57\n",
      "when input is tensor([36, 77, 69, 57]) the target: 70\n",
      "when input is tensor([36, 77, 69, 57, 70]) the target: 1\n",
      "when input is tensor([36, 77, 69, 57, 70,  1]) the target: 16\n",
      "when input is tensor([36, 77, 69, 57, 70,  1, 16]) the target: 24\n",
      "when input is tensor([36, 77, 69, 57, 70,  1, 16, 24]) the target: 1\n"
     ]
    }
   ],
   "source": [
    "# showing how the prediction works\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cddcaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 2,  0, 36, 77, 69, 57, 70,  1],\n",
      "        [75, 61, 76, 75,  1, 76, 64, 61],\n",
      "        [57, 74, 61, 57,  0, 36, 77, 69],\n",
      "        [37,  1, 75, 61, 61, 13,  1, 48]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 0, 36, 77, 69, 57, 70,  1, 16],\n",
      "        [61, 76, 75,  1, 76, 64, 61,  1],\n",
      "        [74, 61, 57,  0, 36, 77, 69, 57],\n",
      "        [ 1, 75, 61, 61, 13,  1, 48, 64]])\n",
      "-------\n",
      "when input is [2] the target: 0\n",
      "when input is [2, 0] the target: 36\n",
      "when input is [2, 0, 36] the target: 77\n",
      "when input is [2, 0, 36, 77] the target: 69\n",
      "when input is [2, 0, 36, 77, 69] the target: 57\n",
      "when input is [2, 0, 36, 77, 69, 57] the target: 70\n",
      "when input is [2, 0, 36, 77, 69, 57, 70] the target: 1\n",
      "when input is [2, 0, 36, 77, 69, 57, 70, 1] the target: 16\n",
      "when input is [75] the target: 61\n",
      "when input is [75, 61] the target: 76\n",
      "when input is [75, 61, 76] the target: 75\n",
      "when input is [75, 61, 76, 75] the target: 1\n",
      "when input is [75, 61, 76, 75, 1] the target: 76\n",
      "when input is [75, 61, 76, 75, 1, 76] the target: 64\n",
      "when input is [75, 61, 76, 75, 1, 76, 64] the target: 61\n",
      "when input is [75, 61, 76, 75, 1, 76, 64, 61] the target: 1\n",
      "when input is [57] the target: 74\n",
      "when input is [57, 74] the target: 61\n",
      "when input is [57, 74, 61] the target: 57\n",
      "when input is [57, 74, 61, 57] the target: 0\n",
      "when input is [57, 74, 61, 57, 0] the target: 36\n",
      "when input is [57, 74, 61, 57, 0, 36] the target: 77\n",
      "when input is [57, 74, 61, 57, 0, 36, 77] the target: 69\n",
      "when input is [57, 74, 61, 57, 0, 36, 77, 69] the target: 57\n",
      "when input is [37] the target: 1\n",
      "when input is [37, 1] the target: 75\n",
      "when input is [37, 1, 75] the target: 61\n",
      "when input is [37, 1, 75, 61] the target: 61\n",
      "when input is [37, 1, 75, 61, 61] the target: 13\n",
      "when input is [37, 1, 75, 61, 61, 13] the target: 1\n",
      "when input is [37, 1, 75, 61, 61, 13, 1] the target: 48\n",
      "when input is [37, 1, 75, 61, 61, 13, 1, 48] the target: 64\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) # set seed for reproducibility\n",
    "batch_size = 4 # number of independent sequences being processed\n",
    "block_size = 8 # maximum context length for predictions\n",
    "\n",
    "# generates a batch of data\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dfa72d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 101])\n",
      "tensor(5.2723, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "VYüòâ(g/g6M<gUHS(c&D15üòÇüôÇuu/rüòêW-qüòÜTkK?oüôÇelÊπòqXog<üòõYH(m\"f?>üòÇ%Eüòêez:4XOuBE7e~_Aee√©qF9aRmQiB(ÁïôE5%t‚Äù\n",
      "pk'!‚Äù<kf\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337) # set seed for reproducibility\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token reads off the logits for the next token\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape # batch, time, channels\n",
    "            # adjusting to match cross_entropy\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "        \n",
    "            # checking quality of predictions\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    # extends each batch (B) in the time (T) dimension for max_new_tokens\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context of some characters in a batch\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "# generating symbols\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens = 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd772dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # learning rate (lr) is 1e-3 due to small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30361a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2629356384277344\n"
     ]
    }
   ],
   "source": [
    "# training with bigram model\n",
    "\n",
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True) # zeroing all the gradients from previous step\n",
    "    loss.backward() # getting the gradients from all of the parameters\n",
    "    optimizer.step() # using gradients to update parameters\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3ac0ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Humooo Hut bantrigou rtitreherad mast awe Ste ftooume ou?f lfoug. be. i5Aheanbuse O cek ind, y an t \n"
     ]
    }
   ],
   "source": [
    "# generation of data after training\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens = 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375c656b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self-attention\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# a single Head performing self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "# weight calculation providing averages for past and current tokens in a data-dependent way\n",
    "wei =  q @ k.transpose(-2, -1) # matrix multiplication: (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T)) # lower triangular matrix\n",
    "# wei = torch.zeros((T,T)) # provides a constant weighting regardless of the data\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # triangular masking\n",
    "wei = F.softmax(wei, dim=-1) # exponentiates and normalizes in order to create the weighting (-inf will turn into 0)\n",
    "\n",
    "v = value(x) # aggregated elements\n",
    "out = wei @ v # changes output to head_size dimensions\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c27a6962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb70418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
       "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
       "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ec469db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled attention\n",
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5 # prevents extreme numbers from converging on one specific number in Softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
